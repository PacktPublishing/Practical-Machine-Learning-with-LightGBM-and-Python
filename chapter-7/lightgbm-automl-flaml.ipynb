{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:16.022356Z",
     "start_time": "2023-05-23T20:12:13.150354700Z"
    }
   },
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import flaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flaml.automl.ml import sklearn_metric_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wind-turbine/train.csv\")\n",
    "numerical_columns = df.describe().columns.values\n",
    "categorical_columns = [\"turbine_status\", \"cloud_level\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:16.372430700Z",
     "start_time": "2023-05-23T20:12:16.026885700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def clean_outliers(frame, feature):\n",
    "    column_data = frame[feature]\n",
    "    column_data = column_data[~np.isnan(column_data)]\n",
    "\n",
    "    mean, std = np.mean(column_data), np.std(column_data)\n",
    "\n",
    "    lower_bound = mean - std * 3\n",
    "    upper_bound = mean + std * 3\n",
    "    frame.loc[((frame[feature] < lower_bound) | (frame[feature] > upper_bound))] = np.nan\n",
    "    return frame\n",
    "\n",
    "\n",
    "def clean_data(frame, is_test=False, skip_impute=False):\n",
    "    for feature in categorical_columns:\n",
    "        frame[feature] = pd.Series(frame[feature], dtype=\"category\")\n",
    "    frame[\"datetime\"] = pd.to_datetime(frame[\"datetime\"])\n",
    "    for f in numerical_columns:\n",
    "        if is_test and f == \"windmill_generated_power(kW/h)\":\n",
    "            pass\n",
    "        frame.loc[frame[f] == -99.0, f] = np.nan\n",
    "        frame.loc[frame[f] == 99.0, f] = np.nan\n",
    "        frame.loc[frame[f] == -999.0, f] = np.nan\n",
    "        frame.loc[frame[f] == 999.0, f] = np.nan\n",
    "\n",
    "        frame = clean_outliers(frame, f)\n",
    "\n",
    "    frame.loc[frame[\"wind_speed(m/s)\"] < 0, \"wind_speed(m/s)\"] = 0\n",
    "    frame.loc[frame[\"wind_speed(m/s)\"] > 113, \"wind_speed(m/s)\"] = 113\n",
    "\n",
    "    frame.loc[frame[\"blade_length(m)\"] < 0, \"blade_length(m)\"] = 0\n",
    "    frame.loc[frame[\"windmill_height(m)\"] < 0, \"windmill_height(m)\"] = 0\n",
    "    frame.loc[frame[\"resistance(ohm)\"] < 0, \"resistance(ohm)\"] = 0\n",
    "\n",
    "    if skip_impute:\n",
    "        for f in frame.columns:\n",
    "            if (is_test and f == \"windmill_generated_power(kW/h)\") or f == \"tracking_id\":\n",
    "                pass\n",
    "            if f in numerical_columns:\n",
    "                frame[f].fillna(frame[f].median(), inplace=True)\n",
    "            else:\n",
    "                frame[f].fillna(frame[f].mode()[0], inplace=True)\n",
    "    frame.drop_duplicates(subset=\"tracking_id\", keep=\"last\", inplace=True)\n",
    "    frame.drop(frame[frame[\"tracking_id\"].isnull()].index, inplace=True)\n",
    "    return frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:16.382983200Z",
     "start_time": "2023-05-23T20:12:16.380971200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = clean_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:16.469519200Z",
     "start_time": "2023-05-23T20:12:16.385008700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id=\"wind-turbine\")\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"wind-turbine\",\n",
    "    dataframe=df,\n",
    "    index=\"tracking_id\"\n",
    ")\n",
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es, target_dataframe_name=\"wind-turbine\",\n",
    "    trans_primitives=[\"day\", \"year\", \"month\", \"weekday\"],\n",
    "    max_depth=1)\n",
    "feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_defs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:17.102684600Z",
     "start_time": "2023-05-23T20:12:16.476014600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X = feature_matrix_enc.drop(columns=[\"windmill_generated_power(kW/h)\", \"generator_temperature(Â°C)\"], axis=1)\n",
    "y = feature_matrix_enc[\"windmill_generated_power(kW/h)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T20:12:31.328539400Z",
     "start_time": "2023-05-23T20:12:31.325393700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 05-23 11:57:29] {1693} INFO - task = regression\n",
      "[flaml.automl.logger: 05-23 11:57:29] {1700} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 05-23 11:57:29] {1703} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 05-23 11:57:29] {1801} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 05-23 11:57:29] {1911} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2347} INFO - Estimated sufficient time budget=675s. Estimated necessary time budget=5s.\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.3s,\testimator lgbm's best error=0.6249,\tbest estimator lgbm's best error=0.6249\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.6249,\tbest estimator lgbm's best error=0.6249\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.3321,\tbest estimator lgbm's best error=0.3321\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.5s,\testimator xgboost's best error=2.7313,\tbest estimator lgbm's best error=0.3321\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.6s,\testimator lgbm's best error=0.1225,\tbest estimator lgbm's best error=0.1225\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.7s,\testimator lgbm's best error=0.1225,\tbest estimator lgbm's best error=0.1225\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2394} INFO -  at 0.8s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:29] {2221} INFO - iteration 7, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 0.9s,\testimator extra_tree's best error=0.4005,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.0s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.1s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.1s,\testimator xgboost's best error=2.7313,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.2s,\testimator xgboost's best error=0.7713,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.3s,\testimator xgboost's best error=0.2404,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.4s,\testimator xgboost's best error=0.2404,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.5s,\testimator extra_tree's best error=0.2307,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.5s,\testimator xgboost's best error=0.2404,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.6s,\testimator extra_tree's best error=0.2307,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 17, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2394} INFO -  at 1.7s,\testimator rf's best error=0.3936,\tbest estimator lgbm's best error=0.0927\n",
      "[flaml.automl.logger: 05-23 11:57:30] {2221} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2394} INFO -  at 2.0s,\testimator lgbm's best error=0.0763,\tbest estimator lgbm's best error=0.0763\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2221} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2394} INFO -  at 2.1s,\testimator xgboost's best error=0.1153,\tbest estimator lgbm's best error=0.0763\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2221} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2394} INFO -  at 2.3s,\testimator rf's best error=0.1195,\tbest estimator lgbm's best error=0.0763\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2221} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2394} INFO -  at 2.4s,\testimator xgboost's best error=0.1105,\tbest estimator lgbm's best error=0.0763\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2221} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2394} INFO -  at 2.5s,\testimator lgbm's best error=0.0763,\tbest estimator lgbm's best error=0.0763\n",
      "[flaml.automl.logger: 05-23 11:57:31] {2221} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:33] {2394} INFO -  at 4.8s,\testimator lgbm's best error=0.0518,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:33] {2221} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2394} INFO -  at 5.0s,\testimator extra_tree's best error=0.1445,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2221} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2394} INFO -  at 5.1s,\testimator extra_tree's best error=0.0950,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2221} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2394} INFO -  at 5.3s,\testimator rf's best error=0.1195,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2221} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2394} INFO -  at 5.4s,\testimator extra_tree's best error=0.0950,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2221} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2394} INFO -  at 5.6s,\testimator extra_tree's best error=0.0894,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:34] {2221} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:35] {2394} INFO -  at 6.0s,\testimator rf's best error=0.0788,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:35] {2221} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:39] {2394} INFO -  at 10.5s,\testimator lgbm's best error=0.0518,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:39] {2221} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:41] {2394} INFO -  at 12.8s,\testimator lgbm's best error=0.0518,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:41] {2221} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2394} INFO -  at 13.3s,\testimator rf's best error=0.0532,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2221} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2394} INFO -  at 13.4s,\testimator xgboost's best error=0.0837,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2221} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2394} INFO -  at 13.9s,\testimator rf's best error=0.0532,\tbest estimator lgbm's best error=0.0518\n",
      "[flaml.automl.logger: 05-23 11:57:42] {2221} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:43] {2394} INFO -  at 14.3s,\testimator rf's best error=0.0503,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:43] {2221} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:43] {2394} INFO -  at 14.5s,\testimator extra_tree's best error=0.0894,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:43] {2221} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2394} INFO -  at 14.9s,\testimator xgboost's best error=0.0571,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2221} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2394} INFO -  at 15.0s,\testimator xgboost's best error=0.0571,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2221} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2394} INFO -  at 15.5s,\testimator rf's best error=0.0503,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2221} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2394} INFO -  at 15.6s,\testimator xgboost's best error=0.0571,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:44] {2221} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:45] {2394} INFO -  at 16.2s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:45] {2221} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 11:57:46] {2394} INFO -  at 17.5s,\testimator lgbm's best error=0.0511,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:46] {2221} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:46] {2394} INFO -  at 17.8s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:46] {2221} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2394} INFO -  at 18.0s,\testimator extra_tree's best error=0.0747,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2221} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2394} INFO -  at 18.2s,\testimator extra_tree's best error=0.0747,\tbest estimator rf's best error=0.0503\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2221} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2394} INFO -  at 18.7s,\testimator rf's best error=0.0461,\tbest estimator rf's best error=0.0461\n",
      "[flaml.automl.logger: 05-23 11:57:47] {2221} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2394} INFO -  at 18.9s,\testimator extra_tree's best error=0.0747,\tbest estimator rf's best error=0.0461\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2221} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2394} INFO -  at 19.3s,\testimator rf's best error=0.0461,\tbest estimator rf's best error=0.0461\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2221} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2394} INFO -  at 19.8s,\testimator rf's best error=0.0461,\tbest estimator rf's best error=0.0461\n",
      "[flaml.automl.logger: 05-23 11:57:48] {2221} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:57:49] {2394} INFO -  at 20.1s,\testimator extra_tree's best error=0.0747,\tbest estimator rf's best error=0.0461\n",
      "[flaml.automl.logger: 05-23 11:57:49] {2221} INFO - iteration 51, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:49] {2394} INFO -  at 20.7s,\testimator rf's best error=0.0446,\tbest estimator rf's best error=0.0446\n",
      "[flaml.automl.logger: 05-23 11:57:49] {2221} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:50] {2394} INFO -  at 21.0s,\testimator rf's best error=0.0446,\tbest estimator rf's best error=0.0446\n",
      "[flaml.automl.logger: 05-23 11:57:50] {2221} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:51] {2394} INFO -  at 22.3s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:51] {2221} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:52] {2394} INFO -  at 23.1s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:52] {2221} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:53] {2394} INFO -  at 23.9s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:53] {2221} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:55] {2394} INFO -  at 26.3s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:55] {2221} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:56] {2394} INFO -  at 27.1s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:56] {2221} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:57:56] {2394} INFO -  at 27.4s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:56] {2221} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2394} INFO -  at 29.9s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2221} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2394} INFO -  at 30.1s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2221} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2394} INFO -  at 30.3s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2221} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2394} INFO -  at 30.6s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2221} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2394} INFO -  at 30.8s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:57:59] {2221} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:00] {2394} INFO -  at 31.1s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:00] {2221} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:58:01] {2394} INFO -  at 32.3s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:01] {2221} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:01] {2394} INFO -  at 32.4s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:01] {2221} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:02] {2394} INFO -  at 33.1s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:02] {2221} INFO - iteration 68, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:02] {2394} INFO -  at 33.3s,\testimator extra_tree's best error=0.0747,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:02] {2221} INFO - iteration 69, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:58:04] {2394} INFO -  at 35.7s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:04] {2221} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2394} INFO -  at 36.1s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2221} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2394} INFO -  at 36.3s,\testimator xgb_limitdepth's best error=0.0551,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2221} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2394} INFO -  at 36.7s,\testimator xgb_limitdepth's best error=0.0546,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:05] {2221} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:06] {2394} INFO -  at 37.1s,\testimator extra_tree's best error=0.0643,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:06] {2221} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:06] {2394} INFO -  at 37.3s,\testimator extra_tree's best error=0.0643,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:06] {2221} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:07] {2394} INFO -  at 38.0s,\testimator extra_tree's best error=0.0590,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:07] {2221} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:58:07] {2394} INFO -  at 38.7s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:07] {2221} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:58:10] {2394} INFO -  at 41.3s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:10] {2221} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2394} INFO -  at 41.9s,\testimator extra_tree's best error=0.0590,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2221} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2394} INFO -  at 42.0s,\testimator xgboost's best error=0.0503,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2221} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2394} INFO -  at 42.7s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:11] {2221} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 11:58:13] {2394} INFO -  at 44.0s,\testimator extra_tree's best error=0.0587,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:13] {2221} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 05-23 11:58:14] {2394} INFO -  at 44.9s,\testimator rf's best error=0.0423,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:14] {2221} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:58:17] {2394} INFO -  at 47.9s,\testimator xgboost's best error=0.0472,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:17] {2221} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:58:17] {2394} INFO -  at 48.1s,\testimator xgboost's best error=0.0472,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:17] {2221} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 11:58:29] {2394} INFO -  at 60.0s,\testimator xgboost's best error=0.0472,\tbest estimator rf's best error=0.0423\n",
      "[flaml.automl.logger: 05-23 11:58:30] {2630} INFO - retrain rf for 1.4s\n",
      "[flaml.automl.logger: 05-23 11:58:30] {2633} INFO - retrained model: RandomForestRegressor(max_features=0.4977274222126191, max_leaf_nodes=1083,\n",
      "                      n_estimators=85, n_jobs=-1, random_state=12032022)\n",
      "[flaml.automl.logger: 05-23 11:58:30] {1941} INFO - fit succeeded\n",
      "[flaml.automl.logger: 05-23 11:58:30] {1942} INFO - Time taken to find the best model: 22.328996181488037\n"
     ]
    }
   ],
   "source": [
    "automl = flaml.AutoML()\n",
    "automl.fit(X, y, task=\"regression\", time_budget=60)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T09:58:30.548330400Z",
     "start_time": "2023-05-23T09:57:29.120890200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.9878605489721696\n",
      "MSE: 0.08090827806554425\n"
     ]
    }
   ],
   "source": [
    "y_pred = automl.predict(X)\n",
    "print(f\"r2: {1 - sklearn_metric_loss_score('r2', y_pred, y)}\")\n",
    "print(f\"MSE: {sklearn_metric_loss_score('mse', y_pred, y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T09:58:30.649851100Z",
     "start_time": "2023-05-23T09:58:30.552871900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 85, 'max_features': 0.4977274222126191, 'max_leaves': 1083}\n",
      "{'lgbm': {'n_estimators': 248, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.3239297756196601, 'log_max_bin': 9, 'colsample_bytree': 0.7330450035989674, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.02411339190861214}, 'rf': {'n_estimators': 85, 'max_features': 0.4977274222126191, 'max_leaves': 1083}, 'xgboost': {'n_estimators': 43, 'max_leaves': 50, 'min_child_weight': 31.942115732268565, 'learning_rate': 0.09485720113896808, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.847756342161632, 'colsample_bytree': 0.8136549849411188, 'reg_alpha': 0.019387994312089204, 'reg_lambda': 0.08649036623112866}, 'extra_tree': {'n_estimators': 147, 'max_features': 0.5744573026671392, 'max_leaves': 3932}, 'xgb_limitdepth': {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 1.4414106781003007, 'learning_rate': 0.36537736318193215, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9468117873770695, 'reg_alpha': 0.025118956715098555, 'reg_lambda': 5.047693393974604}}\n",
      "22.328996181488037\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_config)\n",
    "print(automl.best_config_per_estimator)\n",
    "print(automl.time_to_find_best_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T09:58:30.654947200Z",
     "start_time": "2023-05-23T09:58:30.649341900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customizing fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "automl = flaml.AutoML()\n",
    "custom_hp = {\n",
    "    \"learning_rate\": {\n",
    "        \"domain\": flaml.tune.loguniform(0.0001, 0.05)\n",
    "    }\n",
    "}\n",
    "automl.fit(X, y, task=\"regression\", time_budget=120,\n",
    "           metric=\"mse\",\n",
    "           estimator_list=[\"lgbm\", \"xgboost\", \"rf\"],\n",
    "           custom_hp={\n",
    "               \"lgbm\": custom_hp\n",
    "           },\n",
    "           hpo_method=\"bs\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T09:58:30.667024300Z",
     "start_time": "2023-05-23T09:58:30.654947200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zero-Shot AutoML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "LGBMRegressor(colsample_bytree=0.7019911744574896,\n              learning_rate=0.022635758411078528, max_bin=511,\n              min_child_samples=2, n_estimators=4797, num_leaves=122,\n              reg_alpha=0.004252223402511765, reg_lambda=0.11288241427227624,\n              verbose=-1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.7019911744574896,\n              learning_rate=0.022635758411078528, max_bin=511,\n              min_child_samples=2, n_estimators=4797, num_leaves=122,\n              reg_alpha=0.004252223402511765, reg_lambda=0.11288241427227624,\n              verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.7019911744574896,\n              learning_rate=0.022635758411078528, max_bin=511,\n              min_child_samples=2, n_estimators=4797, num_leaves=122,\n              reg_alpha=0.004252223402511765, reg_lambda=0.11288241427227624,\n              verbose=-1)</pre></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flaml.default import LGBMRegressor\n",
    "\n",
    "zs_model = LGBMRegressor()\n",
    "zs_model.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T10:07:16.564503100Z",
     "start_time": "2023-05-23T09:59:09.386353600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.9999520158503908\n",
      "MSE: 0.0003198097599648468\n"
     ]
    }
   ],
   "source": [
    "y_pred = zs_model.predict(X)\n",
    "print(f\"r2: {1 - sklearn_metric_loss_score('r2', y_pred, y)}\")\n",
    "print(f\"MSE: {sklearn_metric_loss_score('mse', y_pred, y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T10:07:18.727381700Z",
     "start_time": "2023-05-23T10:07:16.566017600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scikit-learn pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "set_config(display=\"diagram\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:29:30.307474500Z",
     "start_time": "2023-05-23T11:29:30.288593100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wind-turbine/train.csv\")\n",
    "numerical_columns = df.describe().columns.values\n",
    "categorical_columns = [\"turbine_status\", \"cloud_level\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:29:49.557974300Z",
     "start_time": "2023-05-23T11:29:49.400297900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "df = clean_data(df, skip_impute=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:29:53.653804400Z",
     "start_time": "2023-05-23T11:29:53.535989200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        es = ft.EntitySet(id=\"wind-turbine\")\n",
    "        es = es.add_dataframe(\n",
    "            dataframe_name=\"wind-turbine\",\n",
    "            dataframe=df,\n",
    "            index=\"tracking_id\"\n",
    "        )\n",
    "\n",
    "        feature_matrix, feature_defs = ft.dfs(\n",
    "            entityset=es, target_dataframe_name=\"wind-turbine\",\n",
    "            trans_primitives=[\"day\", \"year\", \"month\", \"weekday\"],\n",
    "            max_depth=1)\n",
    "        feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_defs)\n",
    "        return feature_matrix_enc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:29:31.391960400Z",
     "start_time": "2023-05-23T11:29:31.366670700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('custom', CustomTransformer()),\n                ('automl',\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list='auto',\n                        eval_method='auto', fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method='auto',\n                        keep_search_state=False, learner_selector='sample',\n                        log_file_name='', log_training_metric=False,\n                        log_type='better', max_iter=None, mem_thres=4294967296,\n                        metric='auto', metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom&#x27;, CustomTransformer()),\n                (&#x27;automl&#x27;,\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list=&#x27;auto&#x27;,\n                        eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n                        keep_search_state=False, learner_selector=&#x27;sample&#x27;,\n                        log_file_name=&#x27;&#x27;, log_training_metric=False,\n                        log_type=&#x27;better&#x27;, max_iter=None, mem_thres=4294967296,\n                        metric=&#x27;auto&#x27;, metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom&#x27;, CustomTransformer()),\n                (&#x27;automl&#x27;,\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list=&#x27;auto&#x27;,\n                        eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n                        keep_search_state=False, learner_selector=&#x27;sample&#x27;,\n                        log_file_name=&#x27;&#x27;, log_training_metric=False,\n                        log_type=&#x27;better&#x27;, max_iter=None, mem_thres=4294967296,\n                        metric=&#x27;auto&#x27;, metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(append_log=False, auto_augment=True, custom_hp={},\n       cv_score_agg_func=None, early_stop=False, ensemble=False,\n       estimator_list=&#x27;auto&#x27;, eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n       force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n       keep_search_state=False, learner_selector=&#x27;sample&#x27;, log_file_name=&#x27;&#x27;,\n       log_training_metric=False, log_type=&#x27;better&#x27;, max_iter=None,\n       mem_thres=4294967296, metric=&#x27;auto&#x27;, metric_constraints=[],\n       min_sample_size=10000, mlflow_logging=True, model_history=False,\n       n_concurrent_trials=1, n_jobs=-1, n_splits=5, pred_time_limit=inf,\n       preserve_checkpoint=True, retrain_full=True, ...)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_pipeline = Pipeline([\n",
    "    (\"custom\", CustomTransformer()),\n",
    "    (\"automl\", flaml.AutoML())\n",
    "])\n",
    "automl_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:30:32.096548200Z",
     "start_time": "2023-05-23T11:30:32.025663600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "X = feature_matrix_enc.drop(columns=[\"windmill_generated_power(kW/h)\", \"generator_temperature(Â°C)\"], axis=1)\n",
    "y = feature_matrix_enc[\"windmill_generated_power(kW/h)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:30:37.428705300Z",
     "start_time": "2023-05-23T11:30:37.407617600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"task\": \"regression\", \"time_budget\": 5\n",
    "}\n",
    "pipeline_settings = {\n",
    "    f\"automl__{key}\": value for key, value in automl_settings.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:30:40.325351900Z",
     "start_time": "2023-05-23T11:30:40.305733700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 05-23 13:30:43] {1693} INFO - task = regression\n",
      "[flaml.automl.logger: 05-23 13:30:43] {1700} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 05-23 13:30:43] {1703} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 05-23 13:30:43] {1801} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 05-23 13:30:43] {1911} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2347} INFO - Estimated sufficient time budget=466s. Estimated necessary time budget=3s.\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.3s,\testimator lgbm's best error=0.4744,\tbest estimator lgbm's best error=0.4744\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.3s,\testimator lgbm's best error=0.4744,\tbest estimator lgbm's best error=0.4744\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.1190,\tbest estimator lgbm's best error=0.1190\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.5s,\testimator xgboost's best error=2.5925,\tbest estimator lgbm's best error=0.1190\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.5s,\testimator extra_tree's best error=0.1539,\tbest estimator lgbm's best error=0.1190\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.6s,\testimator lgbm's best error=0.0058,\tbest estimator lgbm's best error=0.0058\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.7s,\testimator lgbm's best error=0.0058,\tbest estimator lgbm's best error=0.0058\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2394} INFO -  at 0.8s,\testimator lgbm's best error=0.0026,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:43] {2221} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 0.9s,\testimator rf's best error=0.0867,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.0s,\testimator lgbm's best error=0.0026,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.1s,\testimator lgbm's best error=0.0026,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.3s,\testimator rf's best error=0.0058,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.4s,\testimator rf's best error=0.0058,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.5s,\testimator xgboost's best error=2.5925,\tbest estimator lgbm's best error=0.0026\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2394} INFO -  at 1.8s,\testimator rf's best error=0.0008,\tbest estimator rf's best error=0.0008\n",
      "[flaml.automl.logger: 05-23 13:30:44] {2221} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2394} INFO -  at 1.9s,\testimator extra_tree's best error=0.0359,\tbest estimator rf's best error=0.0008\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2221} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2394} INFO -  at 2.3s,\testimator rf's best error=0.0002,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2221} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2394} INFO -  at 2.4s,\testimator extra_tree's best error=0.0359,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2221} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2394} INFO -  at 2.5s,\testimator lgbm's best error=0.0010,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2221} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2394} INFO -  at 2.6s,\testimator extra_tree's best error=0.0048,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:45] {2221} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.0s,\testimator rf's best error=0.0002,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.0s,\testimator xgboost's best error=0.5742,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.1s,\testimator lgbm's best error=0.0010,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 23, current learner rf\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.5s,\testimator rf's best error=0.0002,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.6s,\testimator extra_tree's best error=0.0031,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.8s,\testimator extra_tree's best error=0.0031,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2394} INFO -  at 3.8s,\testimator xgboost's best error=0.0248,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:46] {2221} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 3.9s,\testimator xgboost's best error=0.0248,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.0s,\testimator xgboost's best error=0.0248,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.0s,\testimator xgboost's best error=0.0051,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.3s,\testimator lgbm's best error=0.0010,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.4s,\testimator lgbm's best error=0.0004,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.5s,\testimator lgbm's best error=0.0004,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.6s,\testimator xgboost's best error=0.0051,\tbest estimator rf's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.8s,\testimator lgbm's best error=0.0002,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2394} INFO -  at 4.8s,\testimator xgboost's best error=0.0051,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:47] {2221} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 05-23 13:30:48] {2394} INFO -  at 5.0s,\testimator extra_tree's best error=0.0017,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:48] {2221} INFO - iteration 37, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-23 13:30:48] {2394} INFO -  at 5.0s,\testimator xgb_limitdepth's best error=2.9105,\tbest estimator lgbm's best error=0.0002\n",
      "[flaml.automl.logger: 05-23 13:30:48] {2630} INFO - retrain lgbm for 0.1s\n",
      "[flaml.automl.logger: 05-23 13:30:48] {2633} INFO - retrained model: LGBMRegressor(colsample_bytree=0.7656467580403348, learning_rate=1.0,\n",
      "              max_bin=1023, min_child_samples=3, n_estimators=99, num_leaves=4,\n",
      "              reg_alpha=0.0009765625, reg_lambda=0.006290083866428512,\n",
      "              verbose=-1)\n",
      "[flaml.automl.logger: 05-23 13:30:48] {1941} INFO - fit succeeded\n",
      "[flaml.automl.logger: 05-23 13:30:48] {1942} INFO - Time taken to find the best model: 4.767624616622925\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('custom', CustomTransformer()),\n                ('automl',\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list='auto',\n                        eval_method='auto', fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method='auto',\n                        keep_search_state=False, learner_selector='sample',\n                        log_file_name='', log_training_metric=False,\n                        log_type='better', max_iter=None, mem_thres=4294967296,\n                        metric='auto', metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom&#x27;, CustomTransformer()),\n                (&#x27;automl&#x27;,\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list=&#x27;auto&#x27;,\n                        eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n                        keep_search_state=False, learner_selector=&#x27;sample&#x27;,\n                        log_file_name=&#x27;&#x27;, log_training_metric=False,\n                        log_type=&#x27;better&#x27;, max_iter=None, mem_thres=4294967296,\n                        metric=&#x27;auto&#x27;, metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom&#x27;, CustomTransformer()),\n                (&#x27;automl&#x27;,\n                 AutoML(append_log=False, auto_augment=True, custom_hp={},\n                        cv_score_agg_func=None, early_stop=False,\n                        ensemble=False, estimator_list=&#x27;auto&#x27;,\n                        eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n                        force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n                        keep_search_state=False, learner_selector=&#x27;sample&#x27;,\n                        log_file_name=&#x27;&#x27;, log_training_metric=False,\n                        log_type=&#x27;better&#x27;, max_iter=None, mem_thres=4294967296,\n                        metric=&#x27;auto&#x27;, metric_constraints=[],\n                        min_sample_size=10000, mlflow_logging=True,\n                        model_history=False, n_concurrent_trials=1, n_jobs=-1,\n                        n_splits=5, pred_time_limit=inf,\n                        preserve_checkpoint=True, retrain_full=True, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(append_log=False, auto_augment=True, custom_hp={},\n       cv_score_agg_func=None, early_stop=False, ensemble=False,\n       estimator_list=&#x27;auto&#x27;, eval_method=&#x27;auto&#x27;, fit_kwargs_by_estimator={},\n       force_cancel=False, free_mem_ratio=0, hpo_method=&#x27;auto&#x27;,\n       keep_search_state=False, learner_selector=&#x27;sample&#x27;, log_file_name=&#x27;&#x27;,\n       log_training_metric=False, log_type=&#x27;better&#x27;, max_iter=None,\n       mem_thres=4294967296, metric=&#x27;auto&#x27;, metric_constraints=[],\n       min_sample_size=10000, mlflow_logging=True, model_history=False,\n       n_concurrent_trials=1, n_jobs=-1, n_splits=5, pred_time_limit=inf,\n       preserve_checkpoint=True, retrain_full=True, ...)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_pipeline.fit(X, y, **pipeline_settings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:30:48.349270300Z",
     "start_time": "2023-05-23T11:30:42.413572700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: lgbm\n",
      "Best hyperparmeter config: {'n_estimators': 99, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 0.7656467580403348, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.006290083866428512}\n",
      "Best accuracy on validation data: 0.9998\n",
      "Training duration of best run: 0.1274 s\n"
     ]
    }
   ],
   "source": [
    "automl = automl_pipeline.steps[1][1]\n",
    "# Get the best config and best learner\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T11:31:11.481877700Z",
     "start_time": "2023-05-23T11:31:11.424852500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
